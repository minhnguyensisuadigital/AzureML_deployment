{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eec64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = Workspace(subscription_id=\"\",\n",
    "               resource_group=\"\",\n",
    "               workspace_name=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a154b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model flair_sample_model\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Download model\n",
    "# urllib.request.urlretrieve(\"https://aka.ms/bidaf-9-model\", \"model.onnx\")\n",
    "\n",
    "# Register model\n",
    "# model = Model.register(ws, model_name=\"bidaf_onnx\", model_path=\"./model.onnx\")\n",
    "\n",
    "model = Model.register(ws, model_name=\"flair_sample_model\", model_path=\"D:\\\\NER\\\\flair_sample_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6eafa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name='myenv')\n",
    "python_packages = ['nltk', 'numpy', 'onnxruntime','flair']\n",
    "\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)\n",
    "\n",
    "inference_config = InferenceConfig(environment=env, source_directory='./source_dir', entry_script='./score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7497a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=0.5, memory_gb=1, auth_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361452dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19604\\1635410260.py:1: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-05-10 10:54:37+07:00 Creating Container Registry if not exists.\n",
      "2023-05-10 10:54:37+07:00 Registering the environment.\n",
      "2023-05-10 10:54:38+07:00 Use the existing image.\n",
      "2023-05-10 10:54:38+07:00 Generating deployment configuration.\n",
      "2023-05-10 10:54:39+07:00 Submitting deployment to compute.\n",
      "2023-05-10 10:54:45+07:00 Checking the status of deployment myservice..\n",
      "2023-05-10 10:58:21+07:00 Checking the status of inference endpoint myservice.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-05-10T03:57:50,453953100+00:00 - rsyslog/run \n",
      "2023-05-10T03:57:50,458919800+00:00 - gunicorn/run \n",
      "2023-05-10T03:57:50,461212200+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,462568900+00:00 | gunicorn/run | ###############################################\n",
      "bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2023-05-10T03:57:50,474975800+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2023-05-10T03:57:50,478303500+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:50,483277800+00:00 - nginx/run \n",
      "2023-05-10T03:57:50,486553300+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,492037800+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,509002000+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230324.v2\n",
      "2023-05-10T03:57:50,523606200+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,533525600+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,543290100+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2023-05-10T03:57:50,554263500+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2023-05-10T03:57:50,565001700+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:51,938191700+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "                      *  /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28\n",
      "base                     /opt/miniconda\n",
      "\n",
      "2023-05-10T03:57:53,827766665+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:53,833106269+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "adal==1.2.7\n",
      "aiohttp==3.8.4\n",
      "aiosignal==1.3.1\n",
      "argcomplete==2.1.2\n",
      "async-timeout==4.0.2\n",
      "attrs==23.1.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.26.4\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.12.0\n",
      "azure-mgmt-authorization==3.0.0\n",
      "azure-mgmt-containerregistry==10.1.0\n",
      "azure-mgmt-core==1.4.0\n",
      "azure-mgmt-keyvault==10.2.1\n",
      "azure-mgmt-resource==22.0.0\n",
      "azure-mgmt-storage==21.0.0\n",
      "azureml-core==1.50.0\n",
      "azureml-dataprep==4.10.7\n",
      "azureml-dataprep-native==38.0.0\n",
      "azureml-dataprep-rslex==2.17.8\n",
      "azureml-dataset-runtime==1.50.0\n",
      "azureml-defaults==1.50.0\n",
      "azureml-inference-server-http==0.8.4\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.0.1\n",
      "beautifulsoup4==4.12.2\n",
      "boto3==1.26.130\n",
      "botocore==1.29.130\n",
      "bpemb==0.3.4\n",
      "cachetools==5.3.0\n",
      "certifi @ file:///croot/certifi_1671487769961/work/certifi\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "cloudpickle==2.2.1\n",
      "cmake==3.26.3\n",
      "coloredlogs==15.0.1\n",
      "conllu==4.5.2\n",
      "contextlib2==21.6.0\n",
      "contourpy==1.0.7\n",
      "cryptography==40.0.2\n",
      "cycler==0.11.0\n",
      "datasets==2.12.0\n",
      "Deprecated==1.2.13\n",
      "dill==0.3.6\n",
      "distro==1.8.0\n",
      "docker==6.1.1\n",
      "dotnetcore2==3.1.23\n",
      "filelock==3.12.0\n",
      "flair==0.12.2\n",
      "Flask==2.2.5\n",
      "Flask-Cors==3.0.10\n",
      "flatbuffers==23.3.3\n",
      "fonttools==4.39.3\n",
      "frozenlist==1.3.3\n",
      "fsspec==2023.5.0\n",
      "ftfy==6.1.1\n",
      "fusepy==3.0.1\n",
      "future==0.18.3\n",
      "gdown==4.4.0\n",
      "gensim==4.3.1\n",
      "google-api-core==2.11.0\n",
      "google-auth==2.17.3\n",
      "googleapis-common-protos==1.59.0\n",
      "gunicorn==20.1.0\n",
      "huggingface-hub==0.14.1\n",
      "humanfriendly==10.0\n",
      "hyperopt==0.2.7\n",
      "idna==3.4\n",
      "importlib-metadata==6.6.0\n",
      "importlib-resources==5.12.0\n",
      "inference-schema==1.5.1\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.1.2\n",
      "Janome==0.4.2\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "joblib==1.2.0\n",
      "jsonpickle==3.0.1\n",
      "jsonschema==4.17.3\n",
      "kiwisolver==1.4.4\n",
      "knack==0.10.1\n",
      "langdetect==1.0.9\n",
      "lit==16.0.3\n",
      "lxml==4.9.2\n",
      "MarkupSafe==2.1.2\n",
      "matplotlib==3.7.1\n",
      "more-itertools==9.1.0\n",
      "mpld3==0.3\n",
      "mpmath==1.3.0\n",
      "msal==1.22.0\n",
      "msal-extensions==1.0.0\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.14\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==3.1\n",
      "nltk==3.8.1\n",
      "numpy==1.23.5\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-cupti-cu11==11.7.101\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "nvidia-cufft-cu11==10.9.0.58\n",
      "nvidia-curand-cu11==10.2.10.91\n",
      "nvidia-cusolver-cu11==11.4.0.1\n",
      "nvidia-cusparse-cu11==11.7.4.91\n",
      "nvidia-nccl-cu11==2.14.3\n",
      "nvidia-nvtx-cu11==11.7.91\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.14.1\n",
      "opencensus==0.11.2\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.9\n",
      "packaging==23.0\n",
      "pandas==2.0.1\n",
      "paramiko==3.1.0\n",
      "pathspec==0.11.1\n",
      "Pillow==9.5.0\n",
      "pkginfo==1.9.6\n",
      "pkgutil_resolve_name==1.3.10\n",
      "portalocker==2.7.0\n",
      "pptree==3.1\n",
      "protobuf==3.20.2\n",
      "psutil==5.9.5\n",
      "py4j==0.10.9.7\n",
      "pyarrow==9.0.0\n",
      "pyasn1==0.5.0\n",
      "pyasn1-modules==0.3.0\n",
      "pycparser==2.21\n",
      "pydantic==1.10.7\n",
      "Pygments==2.15.1\n",
      "PyJWT==2.6.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==23.1.1\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.19.3\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.2\n",
      "pytorch_revgrad==0.2.0\n",
      "pytz==2023.3\n",
      "PyYAML==6.0\n",
      "regex==2023.5.5\n",
      "requests==2.30.0\n",
      "requests-oauthlib==1.3.1\n",
      "responses==0.18.0\n",
      "rsa==4.9\n",
      "s3transfer==0.6.1\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "SecretStorage==3.3.3\n",
      "segtok==1.5.11\n",
      "sentencepiece==0.1.99\n",
      "six==1.16.0\n",
      "smart-open==6.3.0\n",
      "soupsieve==2.4.1\n",
      "sqlitedict==2.1.0\n",
      "sympy==1.11.1\n",
      "tabulate==0.9.0\n",
      "threadpoolctl==3.1.0\n",
      "tokenizers==0.13.3\n",
      "torch==2.0.1\n",
      "tqdm==4.65.0\n",
      "transformer-smaller-training-vocab==0.2.3\n",
      "transformers==4.28.1\n",
      "triton==2.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzdata==2023.3\n",
      "urllib3==1.26.15\n",
      "wcwidth==0.2.6\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.3.4\n",
      "Wikipedia-API==0.5.8\n",
      "wrapt==1.12.1\n",
      "xxhash==3.2.0\n",
      "yarl==1.9.2\n",
      "zipp==3.15.0\n",
      "\n",
      "2023-05-10T03:57:55,413957541+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:55,416873946+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:55,418978850+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2023-05-10T03:57:55,421214053+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:55,424106658+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:59,042545440+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:59,044889944+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:59,046689747+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2023-05-10T03:57:59,048805650+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:59,054304460+00:00 | gunicorn/run | \n",
      "2023-05-10T03:58:02,703641584+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "2023-05-10 03:58:03,062 I [70] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n",
      "2023-05-10 03:58:03,340 I [70] gunicorn.error - Starting gunicorn 20.1.0\n",
      "2023-05-10 03:58:03,341 I [70] gunicorn.error - Listening at: http://0.0.0.0:31311 (70)\n",
      "2023-05-10 03:58:03,341 I [70] gunicorn.error - Using worker: sync\n",
      "2023-05-10 03:58:03,352 I [125] gunicorn.error - Booting worker with pid: 125\n",
      "\n",
      "Azure ML Inferencing HTTP server v0.8.4\n",
      "\n",
      "/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n",
      "  class AMLInferenceServerConfig(pydantic.BaseSettings):\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/source_dir/score.py\n",
      "Model Directory: /var/azureml-app/azureml-models/flair_sample_model/7\n",
      "Config File: None\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Health Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/0.8.4\n",
      "CORS for the specified origins: None\n",
      "Create dedicated endpoint for health: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "2023-05-10 03:58:04,362 I [125] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "Initializing logger\n",
      "2023-05-10 03:58:04,365 I [125] azmlinfsrv - Starting up app insights client\n",
      "2023-05-10 03:58:11,420 I [125] azmlinfsrv.print -     smart_open supports the following transport mechanisms:\n",
      "2023-05-10 03:58:11,420 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,421 I [125] azmlinfsrv.print -     file (smart_open/local_file.py)\n",
      "2023-05-10 03:58:11,421 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,422 I [125] azmlinfsrv.print -     Implements the transport for the file:// schema.\n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print -     ftp (smart_open/ftp.py)\n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,425 I [125] azmlinfsrv.print -     Implements I/O streams over FTP.\n",
      "2023-05-10 03:58:11,426 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,427 I [125] azmlinfsrv.print -     hdfs (smart_open/hdfs.py)\n",
      "2023-05-10 03:58:11,428 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     Implements reading and writing to/from HDFS.\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     http (smart_open/http.py)\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     Implements file-like objects for reading from http.\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     kerberos: boolean, optional\n",
      "        If True, will attempt to use the local Kerberos credentials\n",
      "    user: str, optional\n",
      "        The username for authenticating over HTTP\n",
      "    password: str, optional\n",
      "        The password for authenticating over HTTP\n",
      "    cert: str/tuple, optional\n",
      "        if String, path to ssl client cert file (.pem). If Tuple, (‘cert’, ‘key’)\n",
      "    headers: dict, optional\n",
      "        Any headers to send in the request. If ``None``, the default headers are sent:\n",
      "        ``{'Accept-Encoding': 'identity'}``. To use no headers at all,\n",
      "        set this variable to an empty dict, ``{}``.\n",
      "    buffer_size: int, optional\n",
      "        The buffer size to use when performing I/O.\n",
      "\n",
      "2023-05-10 03:58:11,432 I [125] azmlinfsrv.print -     s3 (smart_open/s3.py)\n",
      "2023-05-10 03:58:11,432 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,433 I [125] azmlinfsrv.print -     Implements file-like objects for reading and writing from/to AWS S3.\n",
      "2023-05-10 03:58:11,434 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,436 I [125] azmlinfsrv.print -     buffer_size: int, optional\n",
      "        The buffer size to use when performing I/O.\n",
      "    min_part_size: int, optional\n",
      "        The minimum part size for multipart uploads.  For writing only.\n",
      "    multipart_upload: bool, optional\n",
      "        Default: `True`\n",
      "        If set to `True`, will use multipart upload for writing to S3. If set\n",
      "        to `False`, S3 upload will use the S3 Single-Part Upload API, which\n",
      "        is more ideal for small file sizes.\n",
      "        For writing only.\n",
      "    version_id: str, optional\n",
      "        Version of the object, used when reading object.\n",
      "        If None, will fetch the most recent version.\n",
      "    defer_seek: boolean, optional\n",
      "        Default: `False`\n",
      "        If set to `True` on a file opened for reading, GetObject will not be\n",
      "        called until the first seek() or read().\n",
      "        Avoids redundant API queries when seeking before reading.\n",
      "    client: object, optional\n",
      "        The S3 client to use when working with boto3.\n",
      "        If you don't specify this, then smart_open will create a new client for you.\n",
      "    client_kwargs: dict, optional\n",
      "        Additional parameters to pass to the relevant functions of the client.\n",
      "        The keys are fully qualified method names, e.g. `S3.Client.create_multipart_upload`.\n",
      "        The values are kwargs to pass to that method each time it is called.\n",
      "    writebuffer: IO[bytes], optional\n",
      "        By default, this module will buffer data in memory using io.BytesIO\n",
      "        when writing. Pass another binary IO instance here to use it instead.\n",
      "        For example, you may pass a file object to buffer to local disk instead\n",
      "        of in RAM. Use this to keep RAM usage low at the expense of additional\n",
      "        disk IO. If you pass in an open file, then you are responsible for\n",
      "        cleaning it up after writing completes.\n",
      "\n",
      "2023-05-10 03:58:11,437 I [125] azmlinfsrv.print -     scp (smart_open/ssh.py)\n",
      "2023-05-10 03:58:11,437 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,438 I [125] azmlinfsrv.print -     Implements I/O streams over SSH.\n",
      "2023-05-10 03:58:11,438 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,439 I [125] azmlinfsrv.print -     mode: str, optional\n",
      "        The mode to use for opening the file.\n",
      "    host: str, optional\n",
      "        The hostname of the remote machine.  May not be None.\n",
      "    user: str, optional\n",
      "        The username to use to login to the remote machine.\n",
      "        If None, defaults to the name of the current user.\n",
      "    password: str, optional\n",
      "        The password to use to login to the remote machine.\n",
      "    port: int, optional\n",
      "        The port to connect to.\n",
      "    transport_params: dict, optional\n",
      "        Any additional settings to be passed to paramiko.SSHClient.connect\n",
      "\n",
      "2023-05-10 03:58:11,440 I [125] azmlinfsrv.print -     webhdfs (smart_open/webhdfs.py)\n",
      "2023-05-10 03:58:11,442 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,443 I [125] azmlinfsrv.print -     Implements reading and writing to/from WebHDFS.\n",
      "2023-05-10 03:58:11,444 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,446 I [125] azmlinfsrv.print -     min_part_size: int, optional\n",
      "        For writing only.\n",
      "\n",
      "2023-05-10 03:58:11,446 I [125] azmlinfsrv.print -     Examples\n",
      "2023-05-10 03:58:11,447 I [125] azmlinfsrv.print -     --------\n",
      "2023-05-10 03:58:11,447 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,448 I [125] azmlinfsrv.print -     See README.rst\n",
      "2023-05-10 03:58:11,449 I [125] azmlinfsrv.print -     This function also supports transparent compression and decompression \n",
      "2023-05-10 03:58:11,449 I [125] azmlinfsrv.print -     using the following codecs:\n",
      "2023-05-10 03:58:11,450 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,451 I [125] azmlinfsrv.print -     * .bz2\n",
      "2023-05-10 03:58:11,452 I [125] azmlinfsrv.print -     * .gz\n",
      "2023-05-10 03:58:11,452 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,453 I [125] azmlinfsrv.print -     The function depends on the file extension to determine the appropriate codec.\n",
      "2023-05-10 03:58:11,455 I [125] azmlinfsrv.print -     Supported URI schemes are:\n",
      "2023-05-10 03:58:11,456 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,457 I [125] azmlinfsrv.print -     * file\n",
      "2023-05-10 03:58:11,458 I [125] azmlinfsrv.print -     * ftp\n",
      "2023-05-10 03:58:11,459 I [125] azmlinfsrv.print -     * hdfs\n",
      "2023-05-10 03:58:11,460 I [125] azmlinfsrv.print -     * http\n",
      "2023-05-10 03:58:11,461 I [125] azmlinfsrv.print -     * s3\n",
      "2023-05-10 03:58:11,461 I [125] azmlinfsrv.print -     * scp\n",
      "2023-05-10 03:58:11,463 I [125] azmlinfsrv.print -     * webhdfs\n",
      "2023-05-10 03:58:11,464 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,465 I [125] azmlinfsrv.print -     Valid URI examples::\n",
      "2023-05-10 03:58:11,467 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,467 I [125] azmlinfsrv.print -     * ./local/path/file\n",
      "2023-05-10 03:58:11,468 I [125] azmlinfsrv.print -     * ~/local/path/file\n",
      "2023-05-10 03:58:11,471 I [125] azmlinfsrv.print -     * local/path/file\n",
      "2023-05-10 03:58:11,471 I [125] azmlinfsrv.print -     * ./local/path/file.gz\n",
      "2023-05-10 03:58:11,472 I [125] azmlinfsrv.print -     * file:///home/user/file\n",
      "2023-05-10 03:58:11,473 I [125] azmlinfsrv.print -     * file:///home/user/file.bz2\n",
      "2023-05-10 03:58:11,474 I [125] azmlinfsrv.print -     * ftp://username@host/path/file\n",
      "2023-05-10 03:58:11,476 I [125] azmlinfsrv.print -     * ftp://username:password@host/path/file\n",
      "2023-05-10 03:58:11,477 I [125] azmlinfsrv.print -     * ftp://username:password@host:port/path/file\n",
      "2023-05-10 03:58:11,478 I [125] azmlinfsrv.print -     * ftps://username@host/path/file\n",
      "2023-05-10 03:58:11,479 I [125] azmlinfsrv.print -     * ftps://username:password@host/path/file\n",
      "2023-05-10 03:58:11,481 I [125] azmlinfsrv.print -     * ftps://username:password@host:port/path/file\n",
      "2023-05-10 03:58:11,483 I [125] azmlinfsrv.print -     * hdfs:///path/file\n",
      "2023-05-10 03:58:11,483 I [125] azmlinfsrv.print -     * hdfs://path/file\n",
      "2023-05-10 03:58:11,484 I [125] azmlinfsrv.print -     * viewfs:///path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * viewfs://path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_key:my_secret@my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_key:my_secret@my_server:my_port@my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * ssh://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * ssh://username@host//path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * scp://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * sftp://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * webhdfs://host:port/path/file\n",
      "2023-05-10 03:58:14,436 I [125] azmlinfsrv.user_script - Found user script at /var/azureml-app/source_dir/score.py\n",
      "2023-05-10 03:58:14,437 I [125] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2023-05-10 03:58:14,438 I [125] azmlinfsrv.user_script - Invoking user's init function\n",
      "2023-05-10 03:58:15,769 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n",
      "2023-05-10 03:58:15,917 I [125] azmlinfsrv.user_script - Users's init has completed successfully\n",
      "2023-05-10 03:58:15,920 I [125] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n",
      "2023-05-10 03:58:15,921 I [125] azmlinfsrv - Scoring timeout is set to 60000\n",
      "2023-05-10 03:58:21,362 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:21,364 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:21 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:21,372 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:21,373 I [125] azmlinfsrv - GET /swagger.json 200 1.241ms 2196\n",
      "2023-05-10 03:58:21,374 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:21 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:30,694 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:30,695 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:30 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:30,701 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:30,703 I [125] azmlinfsrv - GET /swagger.json 200 1.277ms 2196\n",
      "2023-05-10 03:58:30,705 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:30 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"myservice\",\n",
    "    [model],\n",
    "    inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ffb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentence[3]: \\\"I love Berlin\\\" \\u2192 [\\\"Berlin\\\"/LOC]\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name=\"myservice\")\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "# Make the request and display the response and logs\n",
    "data = {\n",
    "    \"query\": \"I love Berlin\"\n",
    "}\n",
    "data = json.dumps(data)\n",
    "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d1a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-05-10T03:57:50,453953100+00:00 - rsyslog/run \n",
      "2023-05-10T03:57:50,458919800+00:00 - gunicorn/run \n",
      "2023-05-10T03:57:50,461212200+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,462568900+00:00 | gunicorn/run | ###############################################\n",
      "bash: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2023-05-10T03:57:50,474975800+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2023-05-10T03:57:50,478303500+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:50,483277800+00:00 - nginx/run \n",
      "2023-05-10T03:57:50,486553300+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,492037800+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,509002000+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230324.v2\n",
      "2023-05-10T03:57:50,523606200+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,533525600+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:50,543290100+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2023-05-10T03:57:50,554263500+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2023-05-10T03:57:50,565001700+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:51,938191700+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "                      *  /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28\n",
      "base                     /opt/miniconda\n",
      "\n",
      "2023-05-10T03:57:53,827766665+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:53,833106269+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "adal==1.2.7\n",
      "aiohttp==3.8.4\n",
      "aiosignal==1.3.1\n",
      "argcomplete==2.1.2\n",
      "async-timeout==4.0.2\n",
      "attrs==23.1.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.26.4\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.12.0\n",
      "azure-mgmt-authorization==3.0.0\n",
      "azure-mgmt-containerregistry==10.1.0\n",
      "azure-mgmt-core==1.4.0\n",
      "azure-mgmt-keyvault==10.2.1\n",
      "azure-mgmt-resource==22.0.0\n",
      "azure-mgmt-storage==21.0.0\n",
      "azureml-core==1.50.0\n",
      "azureml-dataprep==4.10.7\n",
      "azureml-dataprep-native==38.0.0\n",
      "azureml-dataprep-rslex==2.17.8\n",
      "azureml-dataset-runtime==1.50.0\n",
      "azureml-defaults==1.50.0\n",
      "azureml-inference-server-http==0.8.4\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.0.1\n",
      "beautifulsoup4==4.12.2\n",
      "boto3==1.26.130\n",
      "botocore==1.29.130\n",
      "bpemb==0.3.4\n",
      "cachetools==5.3.0\n",
      "certifi @ file:///croot/certifi_1671487769961/work/certifi\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "cloudpickle==2.2.1\n",
      "cmake==3.26.3\n",
      "coloredlogs==15.0.1\n",
      "conllu==4.5.2\n",
      "contextlib2==21.6.0\n",
      "contourpy==1.0.7\n",
      "cryptography==40.0.2\n",
      "cycler==0.11.0\n",
      "datasets==2.12.0\n",
      "Deprecated==1.2.13\n",
      "dill==0.3.6\n",
      "distro==1.8.0\n",
      "docker==6.1.1\n",
      "dotnetcore2==3.1.23\n",
      "filelock==3.12.0\n",
      "flair==0.12.2\n",
      "Flask==2.2.5\n",
      "Flask-Cors==3.0.10\n",
      "flatbuffers==23.3.3\n",
      "fonttools==4.39.3\n",
      "frozenlist==1.3.3\n",
      "fsspec==2023.5.0\n",
      "ftfy==6.1.1\n",
      "fusepy==3.0.1\n",
      "future==0.18.3\n",
      "gdown==4.4.0\n",
      "gensim==4.3.1\n",
      "google-api-core==2.11.0\n",
      "google-auth==2.17.3\n",
      "googleapis-common-protos==1.59.0\n",
      "gunicorn==20.1.0\n",
      "huggingface-hub==0.14.1\n",
      "humanfriendly==10.0\n",
      "hyperopt==0.2.7\n",
      "idna==3.4\n",
      "importlib-metadata==6.6.0\n",
      "importlib-resources==5.12.0\n",
      "inference-schema==1.5.1\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.1.2\n",
      "Janome==0.4.2\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "joblib==1.2.0\n",
      "jsonpickle==3.0.1\n",
      "jsonschema==4.17.3\n",
      "kiwisolver==1.4.4\n",
      "knack==0.10.1\n",
      "langdetect==1.0.9\n",
      "lit==16.0.3\n",
      "lxml==4.9.2\n",
      "MarkupSafe==2.1.2\n",
      "matplotlib==3.7.1\n",
      "more-itertools==9.1.0\n",
      "mpld3==0.3\n",
      "mpmath==1.3.0\n",
      "msal==1.22.0\n",
      "msal-extensions==1.0.0\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.14\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==3.1\n",
      "nltk==3.8.1\n",
      "numpy==1.23.5\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-cupti-cu11==11.7.101\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "nvidia-cufft-cu11==10.9.0.58\n",
      "nvidia-curand-cu11==10.2.10.91\n",
      "nvidia-cusolver-cu11==11.4.0.1\n",
      "nvidia-cusparse-cu11==11.7.4.91\n",
      "nvidia-nccl-cu11==2.14.3\n",
      "nvidia-nvtx-cu11==11.7.91\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.14.1\n",
      "opencensus==0.11.2\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.9\n",
      "packaging==23.0\n",
      "pandas==2.0.1\n",
      "paramiko==3.1.0\n",
      "pathspec==0.11.1\n",
      "Pillow==9.5.0\n",
      "pkginfo==1.9.6\n",
      "pkgutil_resolve_name==1.3.10\n",
      "portalocker==2.7.0\n",
      "pptree==3.1\n",
      "protobuf==3.20.2\n",
      "psutil==5.9.5\n",
      "py4j==0.10.9.7\n",
      "pyarrow==9.0.0\n",
      "pyasn1==0.5.0\n",
      "pyasn1-modules==0.3.0\n",
      "pycparser==2.21\n",
      "pydantic==1.10.7\n",
      "Pygments==2.15.1\n",
      "PyJWT==2.6.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==23.1.1\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.19.3\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.2\n",
      "pytorch_revgrad==0.2.0\n",
      "pytz==2023.3\n",
      "PyYAML==6.0\n",
      "regex==2023.5.5\n",
      "requests==2.30.0\n",
      "requests-oauthlib==1.3.1\n",
      "responses==0.18.0\n",
      "rsa==4.9\n",
      "s3transfer==0.6.1\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "SecretStorage==3.3.3\n",
      "segtok==1.5.11\n",
      "sentencepiece==0.1.99\n",
      "six==1.16.0\n",
      "smart-open==6.3.0\n",
      "soupsieve==2.4.1\n",
      "sqlitedict==2.1.0\n",
      "sympy==1.11.1\n",
      "tabulate==0.9.0\n",
      "threadpoolctl==3.1.0\n",
      "tokenizers==0.13.3\n",
      "torch==2.0.1\n",
      "tqdm==4.65.0\n",
      "transformer-smaller-training-vocab==0.2.3\n",
      "transformers==4.28.1\n",
      "triton==2.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzdata==2023.3\n",
      "urllib3==1.26.15\n",
      "wcwidth==0.2.6\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.3.4\n",
      "Wikipedia-API==0.5.8\n",
      "wrapt==1.12.1\n",
      "xxhash==3.2.0\n",
      "yarl==1.9.2\n",
      "zipp==3.15.0\n",
      "\n",
      "2023-05-10T03:57:55,413957541+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:55,416873946+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:55,418978850+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2023-05-10T03:57:55,421214053+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:55,424106658+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:59,042545440+00:00 | gunicorn/run | \n",
      "2023-05-10T03:57:59,044889944+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:59,046689747+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2023-05-10T03:57:59,048805650+00:00 | gunicorn/run | ###############################################\n",
      "2023-05-10T03:57:59,054304460+00:00 | gunicorn/run | \n",
      "2023-05-10T03:58:02,703641584+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "2023-05-10 03:58:03,062 I [70] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n",
      "2023-05-10 03:58:03,340 I [70] gunicorn.error - Starting gunicorn 20.1.0\n",
      "2023-05-10 03:58:03,341 I [70] gunicorn.error - Listening at: http://0.0.0.0:31311 (70)\n",
      "2023-05-10 03:58:03,341 I [70] gunicorn.error - Using worker: sync\n",
      "2023-05-10 03:58:03,352 I [125] gunicorn.error - Booting worker with pid: 125\n",
      "\n",
      "Azure ML Inferencing HTTP server v0.8.4\n",
      "\n",
      "/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n",
      "  class AMLInferenceServerConfig(pydantic.BaseSettings):\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/source_dir/score.py\n",
      "Model Directory: /var/azureml-app/azureml-models/flair_sample_model/7\n",
      "Config File: None\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Health Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/0.8.4\n",
      "CORS for the specified origins: None\n",
      "Create dedicated endpoint for health: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "2023-05-10 03:58:04,362 I [125] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "Initializing logger\n",
      "2023-05-10 03:58:04,365 I [125] azmlinfsrv - Starting up app insights client\n",
      "2023-05-10 03:58:11,420 I [125] azmlinfsrv.print -     smart_open supports the following transport mechanisms:\n",
      "2023-05-10 03:58:11,420 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,421 I [125] azmlinfsrv.print -     file (smart_open/local_file.py)\n",
      "2023-05-10 03:58:11,421 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,422 I [125] azmlinfsrv.print -     Implements the transport for the file:// schema.\n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print -     ftp (smart_open/ftp.py)\n",
      "2023-05-10 03:58:11,423 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,425 I [125] azmlinfsrv.print -     Implements I/O streams over FTP.\n",
      "2023-05-10 03:58:11,426 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,427 I [125] azmlinfsrv.print -     hdfs (smart_open/hdfs.py)\n",
      "2023-05-10 03:58:11,428 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     Implements reading and writing to/from HDFS.\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     http (smart_open/http.py)\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     Implements file-like objects for reading from http.\n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,431 I [125] azmlinfsrv.print -     kerberos: boolean, optional\n",
      "        If True, will attempt to use the local Kerberos credentials\n",
      "    user: str, optional\n",
      "        The username for authenticating over HTTP\n",
      "    password: str, optional\n",
      "        The password for authenticating over HTTP\n",
      "    cert: str/tuple, optional\n",
      "        if String, path to ssl client cert file (.pem). If Tuple, (‘cert’, ‘key’)\n",
      "    headers: dict, optional\n",
      "        Any headers to send in the request. If ``None``, the default headers are sent:\n",
      "        ``{'Accept-Encoding': 'identity'}``. To use no headers at all,\n",
      "        set this variable to an empty dict, ``{}``.\n",
      "    buffer_size: int, optional\n",
      "        The buffer size to use when performing I/O.\n",
      "\n",
      "2023-05-10 03:58:11,432 I [125] azmlinfsrv.print -     s3 (smart_open/s3.py)\n",
      "2023-05-10 03:58:11,432 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,433 I [125] azmlinfsrv.print -     Implements file-like objects for reading and writing from/to AWS S3.\n",
      "2023-05-10 03:58:11,434 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,436 I [125] azmlinfsrv.print -     buffer_size: int, optional\n",
      "        The buffer size to use when performing I/O.\n",
      "    min_part_size: int, optional\n",
      "        The minimum part size for multipart uploads.  For writing only.\n",
      "    multipart_upload: bool, optional\n",
      "        Default: `True`\n",
      "        If set to `True`, will use multipart upload for writing to S3. If set\n",
      "        to `False`, S3 upload will use the S3 Single-Part Upload API, which\n",
      "        is more ideal for small file sizes.\n",
      "        For writing only.\n",
      "    version_id: str, optional\n",
      "        Version of the object, used when reading object.\n",
      "        If None, will fetch the most recent version.\n",
      "    defer_seek: boolean, optional\n",
      "        Default: `False`\n",
      "        If set to `True` on a file opened for reading, GetObject will not be\n",
      "        called until the first seek() or read().\n",
      "        Avoids redundant API queries when seeking before reading.\n",
      "    client: object, optional\n",
      "        The S3 client to use when working with boto3.\n",
      "        If you don't specify this, then smart_open will create a new client for you.\n",
      "    client_kwargs: dict, optional\n",
      "        Additional parameters to pass to the relevant functions of the client.\n",
      "        The keys are fully qualified method names, e.g. `S3.Client.create_multipart_upload`.\n",
      "        The values are kwargs to pass to that method each time it is called.\n",
      "    writebuffer: IO[bytes], optional\n",
      "        By default, this module will buffer data in memory using io.BytesIO\n",
      "        when writing. Pass another binary IO instance here to use it instead.\n",
      "        For example, you may pass a file object to buffer to local disk instead\n",
      "        of in RAM. Use this to keep RAM usage low at the expense of additional\n",
      "        disk IO. If you pass in an open file, then you are responsible for\n",
      "        cleaning it up after writing completes.\n",
      "\n",
      "2023-05-10 03:58:11,437 I [125] azmlinfsrv.print -     scp (smart_open/ssh.py)\n",
      "2023-05-10 03:58:11,437 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,438 I [125] azmlinfsrv.print -     Implements I/O streams over SSH.\n",
      "2023-05-10 03:58:11,438 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,439 I [125] azmlinfsrv.print -     mode: str, optional\n",
      "        The mode to use for opening the file.\n",
      "    host: str, optional\n",
      "        The hostname of the remote machine.  May not be None.\n",
      "    user: str, optional\n",
      "        The username to use to login to the remote machine.\n",
      "        If None, defaults to the name of the current user.\n",
      "    password: str, optional\n",
      "        The password to use to login to the remote machine.\n",
      "    port: int, optional\n",
      "        The port to connect to.\n",
      "    transport_params: dict, optional\n",
      "        Any additional settings to be passed to paramiko.SSHClient.connect\n",
      "\n",
      "2023-05-10 03:58:11,440 I [125] azmlinfsrv.print -     webhdfs (smart_open/webhdfs.py)\n",
      "2023-05-10 03:58:11,442 I [125] azmlinfsrv.print -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2023-05-10 03:58:11,443 I [125] azmlinfsrv.print -     Implements reading and writing to/from WebHDFS.\n",
      "2023-05-10 03:58:11,444 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,446 I [125] azmlinfsrv.print -     min_part_size: int, optional\n",
      "        For writing only.\n",
      "\n",
      "2023-05-10 03:58:11,446 I [125] azmlinfsrv.print -     Examples\n",
      "2023-05-10 03:58:11,447 I [125] azmlinfsrv.print -     --------\n",
      "2023-05-10 03:58:11,447 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,448 I [125] azmlinfsrv.print -     See README.rst\n",
      "2023-05-10 03:58:11,449 I [125] azmlinfsrv.print -     This function also supports transparent compression and decompression \n",
      "2023-05-10 03:58:11,449 I [125] azmlinfsrv.print -     using the following codecs:\n",
      "2023-05-10 03:58:11,450 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,451 I [125] azmlinfsrv.print -     * .bz2\n",
      "2023-05-10 03:58:11,452 I [125] azmlinfsrv.print -     * .gz\n",
      "2023-05-10 03:58:11,452 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,453 I [125] azmlinfsrv.print -     The function depends on the file extension to determine the appropriate codec.\n",
      "2023-05-10 03:58:11,455 I [125] azmlinfsrv.print -     Supported URI schemes are:\n",
      "2023-05-10 03:58:11,456 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,457 I [125] azmlinfsrv.print -     * file\n",
      "2023-05-10 03:58:11,458 I [125] azmlinfsrv.print -     * ftp\n",
      "2023-05-10 03:58:11,459 I [125] azmlinfsrv.print -     * hdfs\n",
      "2023-05-10 03:58:11,460 I [125] azmlinfsrv.print -     * http\n",
      "2023-05-10 03:58:11,461 I [125] azmlinfsrv.print -     * s3\n",
      "2023-05-10 03:58:11,461 I [125] azmlinfsrv.print -     * scp\n",
      "2023-05-10 03:58:11,463 I [125] azmlinfsrv.print -     * webhdfs\n",
      "2023-05-10 03:58:11,464 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,465 I [125] azmlinfsrv.print -     Valid URI examples::\n",
      "2023-05-10 03:58:11,467 I [125] azmlinfsrv.print - \n",
      "2023-05-10 03:58:11,467 I [125] azmlinfsrv.print -     * ./local/path/file\n",
      "2023-05-10 03:58:11,468 I [125] azmlinfsrv.print -     * ~/local/path/file\n",
      "2023-05-10 03:58:11,471 I [125] azmlinfsrv.print -     * local/path/file\n",
      "2023-05-10 03:58:11,471 I [125] azmlinfsrv.print -     * ./local/path/file.gz\n",
      "2023-05-10 03:58:11,472 I [125] azmlinfsrv.print -     * file:///home/user/file\n",
      "2023-05-10 03:58:11,473 I [125] azmlinfsrv.print -     * file:///home/user/file.bz2\n",
      "2023-05-10 03:58:11,474 I [125] azmlinfsrv.print -     * ftp://username@host/path/file\n",
      "2023-05-10 03:58:11,476 I [125] azmlinfsrv.print -     * ftp://username:password@host/path/file\n",
      "2023-05-10 03:58:11,477 I [125] azmlinfsrv.print -     * ftp://username:password@host:port/path/file\n",
      "2023-05-10 03:58:11,478 I [125] azmlinfsrv.print -     * ftps://username@host/path/file\n",
      "2023-05-10 03:58:11,479 I [125] azmlinfsrv.print -     * ftps://username:password@host/path/file\n",
      "2023-05-10 03:58:11,481 I [125] azmlinfsrv.print -     * ftps://username:password@host:port/path/file\n",
      "2023-05-10 03:58:11,483 I [125] azmlinfsrv.print -     * hdfs:///path/file\n",
      "2023-05-10 03:58:11,483 I [125] azmlinfsrv.print -     * hdfs://path/file\n",
      "2023-05-10 03:58:11,484 I [125] azmlinfsrv.print -     * viewfs:///path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * viewfs://path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_key:my_secret@my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * s3://my_key:my_secret@my_server:my_port@my_bucket/my_key\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * ssh://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * ssh://username@host//path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * scp://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * sftp://username@host/path/file\n",
      "2023-05-10 03:58:11,485 I [125] azmlinfsrv.print -     * webhdfs://host:port/path/file\n",
      "2023-05-10 03:58:14,436 I [125] azmlinfsrv.user_script - Found user script at /var/azureml-app/source_dir/score.py\n",
      "2023-05-10 03:58:14,437 I [125] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2023-05-10 03:58:14,438 I [125] azmlinfsrv.user_script - Invoking user's init function\n",
      "2023-05-10 03:58:15,769 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n",
      "2023-05-10 03:58:15,917 I [125] azmlinfsrv.user_script - Users's init has completed successfully\n",
      "2023-05-10 03:58:15,920 I [125] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n",
      "2023-05-10 03:58:15,921 I [125] azmlinfsrv - Scoring timeout is set to 60000\n",
      "2023-05-10 03:58:21,362 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:21,364 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:21 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:21,372 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:21,373 I [125] azmlinfsrv - GET /swagger.json 200 1.241ms 2196\n",
      "2023-05-10 03:58:21,374 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:21 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:30,694 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:30,695 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:30 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:58:30,701 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:58:30,703 I [125] azmlinfsrv - GET /swagger.json 200 1.277ms 2196\n",
      "2023-05-10 03:58:30,705 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:58:30 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:59:09,403 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:59:09,405 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:59:09 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:59:09,415 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:59:09,415 I [125] azmlinfsrv - GET /swagger.json 200 0.709ms 2196\n",
      "2023-05-10 03:59:09,416 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:59:09 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 03:59:12,077 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 03:59:12,078 I [125] azmlinfsrv.print - {\"query\": \"I love Berlin\"}\n",
      "2023-05-10 03:59:12,158 I [125] azmlinfsrv - POST /score 200 82.101ms 56\n",
      "2023-05-10 03:59:12,160 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:03:59:12 +0000] \"POST /score HTTP/1.0\" 200 56 \"-\" \"python-requests/2.28.2\"\n",
      "2023-05-10 04:11:16,283 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:11:16,290 I [125] azmlinfsrv.print - {\n",
      "    \"query\": \"I love Berlin\"\n",
      "}\n",
      "2023-05-10 04:11:16,310 I [125] azmlinfsrv - POST /score 200 27.526ms 56\n",
      "2023-05-10 04:11:16,313 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:11:16 +0000] \"POST /score HTTP/1.0\" 200 56 \"-\" \"Firecamp/2.7.1\"\n",
      "2023-05-10 04:11:39,726 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:11:39,727 I [125] azmlinfsrv.print - %22query%22=I%20love%20Berlin\n",
      "2023-05-10 04:11:39,734 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:11:39,736 I [125] azmlinfsrv - POST /score 500 9.597ms 92\n",
      "2023-05-10 04:11:39,739 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:11:39 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:11:49,630 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:11:49,630 I [125] azmlinfsrv.print - %22query%22=I%20love%20Berlin\n",
      "2023-05-10 04:11:49,631 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:11:49,631 I [125] azmlinfsrv - POST /score 500 0.928ms 92\n",
      "2023-05-10 04:11:49,632 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:11:49 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:11:55,207 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:11:55,214 I [125] azmlinfsrv.print - query=I%20love%20Berlin\n",
      "2023-05-10 04:11:55,216 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:11:55,216 I [125] azmlinfsrv - POST /score 500 9.480ms 92\n",
      "2023-05-10 04:11:55,220 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:11:55 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:12:24,326 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:12:24,327 I [125] azmlinfsrv.print - {\n",
      "    \"query\": \"I love Berlin\"\n",
      "}\n",
      "2023-05-10 04:12:24,338 I [125] azmlinfsrv - POST /score 200 11.589ms 56\n",
      "2023-05-10 04:12:24,339 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:12:24 +0000] \"POST /score HTTP/1.0\" 200 56 \"-\" \"Firecamp/2.7.1\"\n",
      "2023-05-10 04:13:03,462 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:13:03,462 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:13:03 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 04:13:03,466 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:13:03,467 I [125] azmlinfsrv - GET /swagger.json 200 0.273ms 2196\n",
      "2023-05-10 04:13:03,468 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:13:03 +0000] \"GET /swagger.json HTTP/1.0\" 200 2196 \"-\" \"Go-http-client/1.1\"\n",
      "2023-05-10 04:13:07,060 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:13:07,061 I [125] azmlinfsrv.print - {\"query\": \"I love Berlin\"}\n",
      "2023-05-10 04:13:07,067 I [125] azmlinfsrv - POST /score 200 7.454ms 56\n",
      "2023-05-10 04:13:07,068 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:13:07 +0000] \"POST /score HTTP/1.0\" 200 56 \"-\" \"python-requests/2.28.2\"\n",
      "2023-05-10 04:13:45,452 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:13:45,452 I [125] azmlinfsrv.print - data=I%20love%20Berlin\n",
      "2023-05-10 04:13:45,452 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:13:45,453 I [125] azmlinfsrv - POST /score 500 1.055ms 92\n",
      "2023-05-10 04:13:45,453 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:13:45 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:14:44,572 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:14:44,572 I [125] azmlinfsrv.print - data=I%20love%20Berlin\n",
      "2023-05-10 04:14:44,573 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:14:44,573 I [125] azmlinfsrv - POST /score 500 0.923ms 92\n",
      "2023-05-10 04:14:44,574 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:14:44 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:15:52,792 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:15:52,792 I [125] azmlinfsrv.print - {\n",
      "    \"query\": \"I love Berlin, firecamp\"\n",
      "}\n",
      "2023-05-10 04:15:52,807 I [125] azmlinfsrv - POST /score 200 14.945ms 66\n",
      "2023-05-10 04:15:52,808 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:15:52 +0000] \"POST /score HTTP/1.0\" 200 66 \"-\" \"Firecamp/2.7.1\"\n",
      "2023-05-10 04:16:30,818 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:16:30,818 I [125] azmlinfsrv.print - query=I%20love%20Berlin%2C%20Uipath\n",
      "2023-05-10 04:16:30,819 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:16:30,819 I [125] azmlinfsrv - POST /score 500 1.284ms 92\n",
      "2023-05-10 04:16:30,820 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:16:30 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:21:36,008 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:21:36,009 I [125] azmlinfsrv.print - request=%20%20%20%20%7B%0D%0A%20%20%20%20%27query%27%3A%20%27I%20love%20Berlin%2C%20firecamp%27%0D%0A%20%20%20%20%7D\n",
      "2023-05-10 04:21:36,010 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:21:36,011 I [125] azmlinfsrv - POST /score 500 3.259ms 92\n",
      "2023-05-10 04:21:36,013 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:21:36 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:27:00,736 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:27:00,737 I [125] azmlinfsrv.print - request=%7B%0D%0A%20%20%22query%22%3A%20%22I%20love%20Berlin%2C%20firecamp%22%0D%0A%7D\n",
      "2023-05-10 04:27:00,738 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:27:00,739 I [125] azmlinfsrv - POST /score 500 2.772ms 92\n",
      "2023-05-10 04:27:00,740 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:27:00 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:28:06,173 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:28:06,173 I [125] azmlinfsrv.print - request=%7B%0D%0A%20%20%22query%22%3A%20%22I%20love%20Berlin%2C%20firecamp%22%0D%0A%7D\n",
      "2023-05-10 04:28:06,174 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:28:06,174 I [125] azmlinfsrv - POST /score 500 1.005ms 92\n",
      "2023-05-10 04:28:06,176 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:28:06 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 04:32:15,024 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 04:32:15,024 I [125] azmlinfsrv.print - query=I%20love%20Berlin\n",
      "2023-05-10 04:32:15,025 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 04:32:15,026 I [125] azmlinfsrv - POST /score 500 2.333ms 92\n",
      "2023-05-10 04:32:15,028 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:04:32:15 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:16:49,152 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:16:49,153 I [125] azmlinfsrv.print - query=I%20love%20Berlin\n",
      "2023-05-10 06:16:49,157 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:16:49,157 I [125] azmlinfsrv - POST /score 500 5.777ms 92\n",
      "2023-05-10 06:16:49,159 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:16:49 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:24:23,088 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:24:23,097 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:24:23 +0000] \"GET /?XDEBUG_SESSION_START=phpstorm HTTP/1.0\" 200 7 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\"\n",
      "2023-05-10 06:34:03,941 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:34:03 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:34:04,552 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:34:04 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:34:33,619 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:34:33 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:35:18,099 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:35:18,099 I [125] azmlinfsrv.print - {\n",
      "    \"query\": \"I love Berlin, firecamp\"\n",
      "}\n",
      "2023-05-10 06:35:18,129 I [125] azmlinfsrv - POST /score 200 30.325ms 66\n",
      "2023-05-10 06:35:18,131 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:35:18 +0000] \"POST /score HTTP/1.0\" 200 66 \"-\" \"Firecamp/2.7.1\"\n",
      "2023-05-10 06:35:26,425 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:35:26 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:35:34,808 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:35:34 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:35:51,623 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:35:51 +0000] \"POST /score/ HTTP/1.0\" 404 135 \"-\" \"RestSharp/106.6.10.0\"\n",
      "2023-05-10 06:37:34,145 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:37:34,146 I [125] azmlinfsrv.print - \n",
      "2023-05-10 06:37:34,146 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:37:34,147 I [125] azmlinfsrv - POST /score 500 1.426ms 92\n",
      "2023-05-10 06:37:34,148 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:37:34 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:42:16,331 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:42:16,331 I [125] azmlinfsrv.print - body=I%20love%20Berlin\n",
      "2023-05-10 06:42:16,332 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:42:16,332 I [125] azmlinfsrv - POST /score 500 1.520ms 92\n",
      "2023-05-10 06:42:16,333 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:42:16 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:44:17,116 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:44:17,116 I [125] azmlinfsrv.print - \n",
      "2023-05-10 06:44:17,116 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:44:17,116 I [125] azmlinfsrv - POST /score 500 0.882ms 92\n",
      "2023-05-10 06:44:17,117 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:44:17 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:44:41,845 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:44:41,846 I [125] azmlinfsrv.print - body=I%20love%20berlin\n",
      "2023-05-10 06:44:41,848 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:44:41,848 I [125] azmlinfsrv - POST /score 500 3.486ms 92\n",
      "2023-05-10 06:44:41,850 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:44:41 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:46:44,961 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:46:44,961 I [125] azmlinfsrv.print - {\n",
      "    \"query\": \"I love Berlin, firecamp\"\n",
      "}\n",
      "2023-05-10 06:46:44,979 I [125] azmlinfsrv - POST /score 200 18.301ms 66\n",
      "2023-05-10 06:46:44,981 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:46:44 +0000] \"POST /score HTTP/1.0\" 200 66 \"-\" \"Firecamp/2.7.1\"\n",
      "2023-05-10 06:51:03,614 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:51:03,615 I [125] azmlinfsrv.print - -----------5EFE368F-ECA6-499A-B27A-83AB36116E20\n",
      "Content-Disposition: form-data; name=\"body\"\n",
      "\n",
      "I love berlin\n",
      "-----------5EFE368F-ECA6-499A-B27A-83AB36116E20\n",
      "Content-Disposition: form-data; name=\"body\"; filename=\"test.json\"\n",
      "Content-Type: application/octet-stream\n",
      "\n",
      "{\n",
      "    \"query\": \"I love Berlin, firecamp\"\n",
      "}\n",
      "-----------5EFE368F-ECA6-499A-B27A-83AB36116E20--\n",
      "\n",
      "2023-05-10 06:51:03,616 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:51:03,617 I [125] azmlinfsrv - POST /score 500 2.808ms 92\n",
      "2023-05-10 06:51:03,620 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:51:03 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:56:33,019 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:56:33,019 I [125] azmlinfsrv.print - Parameters=POST\n",
      "2023-05-10 06:56:33,020 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:56:33,021 I [125] azmlinfsrv - POST /score 500 2.084ms 92\n",
      "2023-05-10 06:56:33,022 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:56:33 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:57:06,152 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:57:06,153 I [125] azmlinfsrv.print - Parameters=POST\n",
      "2023-05-10 06:57:06,153 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:57:06,153 I [125] azmlinfsrv - POST /score 500 0.808ms 92\n",
      "2023-05-10 06:57:06,154 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:57:06 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 06:58:49,140 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:58:49,140 I [125] azmlinfsrv.print - {\"query\": \"I love Berlin, firecamp\"}\n",
      "2023-05-10 06:58:49,150 I [125] azmlinfsrv - POST /score 200 10.110ms 66\n",
      "2023-05-10 06:58:49,152 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:58:49 +0000] \"POST /score HTTP/1.0\" 200 66 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 X-Middleton/1\"\n",
      "2023-05-10 06:59:36,770 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 06:59:36,771 I [125] azmlinfsrv.print - Parameters=POST\n",
      "2023-05-10 06:59:36,771 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 06:59:36,771 I [125] azmlinfsrv - POST /score 500 1.117ms 92\n",
      "2023-05-10 06:59:36,772 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:06:59:36 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "2023-05-10 07:00:16,739 W [125] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2023-05-10 07:00:16,739 I [125] azmlinfsrv.print - Parameters=POST\n",
      "2023-05-10 07:00:16,739 E [125] azmlinfsrv - Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 130, in invoke_run\n",
      "    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 154, in <lambda>\n",
      "    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\n",
      "  File \"/var/azureml-app/source_dir/score.py\", line 19, in run\n",
      "    text = json.loads(request)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py\", line 219, in handle_score\n",
      "    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)\n",
      "  File \"/azureml-envs/azureml_bf99e0798ca6a8bdacfb2455262f0b28/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 137, in invoke_run\n",
      "    raise UserScriptException(ex) from ex\n",
      "azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\n",
      "\n",
      "2023-05-10 07:00:16,740 I [125] azmlinfsrv - POST /score 500 0.974ms 92\n",
      "2023-05-10 07:00:16,740 I [125] gunicorn.access - 127.0.0.1 - - [10/May/2023:07:00:16 +0000] \"POST /score HTTP/1.0\" 500 92 \"-\" \"RestSharp/106.15.0.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3115a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://7b7ab5c1-658a-4b2b-b996-9040b928619c.northeurope.azurecontainer.io/score\n",
      "Bearer W6cv8QEcPcrSjFAI3ZMdnAuYOVYBzuuL\n"
     ]
    }
   ],
   "source": [
    "print(scoring_uri)\n",
    "print(headers[\"Authorization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bbede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
